# tools/web_tools.py
"""
ç½‘ç»œæœç´¢å·¥å…·å®ç°
åªæ”¯æŒsearXNGæœç´¢å¼•æ“èšåˆå™¨
"""

import asyncio
import aiohttp
import json
from typing import Dict, List, Any, Optional
from pathlib import Path
from urllib.parse import quote, urljoin
import os
import time


class WebTools:
    """ç½‘ç»œæœç´¢å’ŒWebæ“ä½œå·¥å…·ï¼ˆåªæ”¯æŒsearXNGï¼‰"""

    def __init__(self, project_path: Path, safety_guard):
        self.project_path = project_path
        self.safety_guard = safety_guard
        self.session: Optional[aiohttp.ClientSession] = None
        self.search_engines = {
            "searxng": {
                "url": os.getenv("SEARCHXNG_URL", "http://localhost:8080").rstrip(
                    "/search"
                ),
                "enabled": bool(os.getenv("SEARCHXNG_URL")),
                "description": "è‡ªæ‰˜ç®¡æœç´¢å¼•æ“èšåˆå™¨ï¼ˆé›†æˆGoogleã€Bingã€ç™¾åº¦ã€æœç‹—ç­‰ï¼‰"
            }
        }
        self.last_search_time = {}

    async def _ensure_session(self):
        """ç¡®ä¿HTTPä¼šè¯å­˜åœ¨"""
        if self.session is None or self.session.closed:
            # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´(æ¥è‡ª aacode_config.yaml)
            from config import settings

            web_timeout = settings.timeouts.web_request
            timeout = aiohttp.ClientTimeout(total=web_timeout, connect=10)
            
            # åˆ›å»ºSSLä¸Šä¸‹æ–‡ï¼Œå…è®¸è‡ªç­¾åè¯ä¹¦ï¼ˆç”¨äºæœ¬åœ°searXNGå®ä¾‹ï¼‰
            import ssl
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            connector = aiohttp.TCPConnector(
                limit=100,
                limit_per_host=30,
                force_close=False,
                enable_cleanup_closed=True,
                ssl=ssl_context,
            )
            self.session = aiohttp.ClientSession(
                timeout=timeout,
                connector=connector,
                headers={
                    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                },
            )
        # ç¡®ä¿sessionä¸ä¸ºNone
        assert self.session is not None, "Session should be initialized"

    async def search_web(
        self,
        query: str,
        engine: str = "auto",
        max_results: int = 10,
        safe_search: bool = True,
        **kwargs,
    ) -> Dict[str, Any]:
        """
        ç½‘ç»œæœç´¢ï¼ˆåªæ”¯æŒsearxngï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            engine: æœç´¢å¼•æ“ (åªæ”¯æŒsearxngæˆ–auto)
            max_results: æœ€å¤§ç»“æœæ•°
            safe_search: æ˜¯å¦å¯ç”¨å®‰å…¨æœç´¢

        æ³¨æ„:**kwargs ç”¨äºæ¥æ”¶å¹¶å¿½ç•¥æ¨¡å‹å¯èƒ½ä¼ å…¥çš„é¢å¤–å‚æ•°

        Returns:
            æœç´¢ç»“æœ
        """
        try:
            await self._ensure_session()

            # é€‰æ‹©æœç´¢å¼•æ“
            if engine == "auto":
                engine = self._choose_best_engine()

            if not self.search_engines.get(engine, {}).get("enabled", False):
                return {
                    "success": False,
                    "error": f"æœç´¢å¼•æ“ {engine} ä¸å¯ç”¨",
                    "available_engines": [
                        k for k, v in self.search_engines.items() if v.get("enabled")
                    ],
                }

            # é€Ÿç‡é™åˆ¶æ£€æŸ¥
            if not self._check_rate_limit(engine):
                return {
                    "success": False,
                    "error": f"æœç´¢å¼•æ“ {engine} é€Ÿç‡é™åˆ¶ä¸­,è¯·ç¨åé‡è¯•",
                }

            # æ‰§è¡Œæœç´¢
            results = await self._search_with_fallback(query, engine, max_results, safe_search)
            
            # æ›´æ–°é€Ÿç‡é™åˆ¶
            if results.get("success"):
                used_engine = results.get("engine", engine)
                self.last_search_time[used_engine] = time.time()

            return results

        except Exception as e:
            return {"success": False, "error": f"æœç´¢å¤±è´¥: {str(e)}"}

    async def fetch_url(
        self, url: str, timeout: Optional[int] = None, max_content_length: int = 100000, **kwargs
    ) -> Dict[str, Any]:
        """
        è·å–ç½‘é¡µå†…å®¹

        Args:
            url: ç½‘é¡µURL
            timeout: è¶…æ—¶æ—¶é—´(ç§’),é»˜è®¤ä½¿ç”¨é…ç½®å€¼
            max_content_length: æœ€å¤§å†…å®¹é•¿åº¦

         æ³¨æ„:**kwargs ç”¨äºæ¥æ”¶å¹¶å¿½ç•¥æ¨¡å‹å¯èƒ½ä¼ å…¥çš„é¢å¤–å‚æ•°

        Returns:
             ç½‘é¡µå†…å®¹
        """
        try:
            # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´(æ¥è‡ª aacode_config.yaml)
            if timeout is None:
                from config import settings

                timeout = settings.timeouts.web_request

            await self._ensure_session()
            # ç±»å‹æ£€æŸ¥å™¨éœ€è¦çŸ¥é“sessionä¸ä¸ºNone
            session = self.session
            assert session is not None, "Session should be initialized"

            # URLå®‰å…¨æ£€æŸ¥
            if not self._is_safe_url(url):
                return {"success": False, "error": "URLå®‰å…¨æ£€æŸ¥å¤±è´¥"}

            if timeout is None:
                timeout = 30
            client_timeout = aiohttp.ClientTimeout(total=timeout)
            
            async with session.get(url, timeout=client_timeout) as response:
                content_type = response.headers.get("content-type", "").lower()

                # åªå¤„ç†æ–‡æœ¬å†…å®¹
                if not any(
                    ct in content_type
                    for ct in ["text/html", "text/plain", "application/json"]
                ):
                    return {
                        "success": False,
                        "error": f"ä¸æ”¯æŒçš„å†…å®¹ç±»å‹: {content_type}",
                    }

                content = await response.text(errors="ignore")

                # é™åˆ¶å†…å®¹é•¿åº¦
                if len(content) > max_content_length:
                    content = content[:max_content_length] + "\n...[å†…å®¹å·²æˆªæ–­]"

                return {
                    "success": True,
                    "url": url,
                    "status_code": response.status,
                    "content_type": content_type,
                    "content_length": len(content),
                    "content": content,
                }

        except asyncio.TimeoutError:
            return {"success": False, "error": f"è¯·æ±‚è¶…æ—¶ ({timeout}ç§’)"}
        except Exception as e:
            return {"success": False, "error": f"è·å–ç½‘é¡µå¤±è´¥: {str(e)}"}

    def _choose_best_engine(self) -> str:
        """é€‰æ‹©æœ€ä½³æœç´¢å¼•æ“"""
        # åªæ”¯æŒsearxng
        if self.search_engines.get("searxng", {}).get("enabled", False):
            return "searxng"
        
        # å¦‚æœæ²¡æœ‰å¯ç”¨çš„å¼•æ“ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ""

    async def _search_with_fallback(
        self, query: str, engine: str, max_results: int, safe_search: bool
    ) -> Dict[str, Any]:
        """æœç´¢å®ç°ï¼ˆåªæ”¯æŒsearxngï¼‰"""
        # åªæ”¯æŒsearxng
        if engine == "auto":
            engine = "searxng"
        
        if engine != "searxng":
            return {
                "success": False,
                "error": f"ä¸æ”¯æŒçš„æœç´¢å¼•æ“: {engine}ï¼Œå½“å‰åªæ”¯æŒsearxng",
                "query": query,
                "suggestion": "è¯·é…ç½®SEARCHXNG_URLç¯å¢ƒå˜é‡",
            }
        
        # æ£€æŸ¥searxngæ˜¯å¦å¯ç”¨
        if not self.search_engines.get("searxng", {}).get("enabled", False):
            return {
                "success": False,
                "error": "searxngæœç´¢å¼•æ“æœªå¯ç”¨",
                "query": query,
                "suggestion": "è¯·è®¾ç½®SEARCHXNG_URLç¯å¢ƒå˜é‡æŒ‡å‘æ‚¨çš„searXNGå®ä¾‹",
            }
        
        try:
            print(f"ğŸ” ä½¿ç”¨æœç´¢å¼•æ“: {engine}")
            result = await self._search_searxng(query, max_results, safe_search)
            return result
            
        except Exception as e:
            return {
                "success": False,
                "error": f"searxngæœç´¢å¤±è´¥: {str(e)}",
                "query": query,
                "suggestion": "è¯·æ£€æŸ¥searXNGå®ä¾‹æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸",
            }

    def _check_rate_limit(self, engine: str) -> bool:
        """æ£€æŸ¥é€Ÿç‡é™åˆ¶"""
        last_time = self.last_search_time.get(engine, 0)
        rate_limit = self.search_engines.get(engine, {}).get("rate_limit", 1.0)
        
        # å¯¹äºsearxngï¼Œæ”¾å®½é€Ÿç‡é™åˆ¶ï¼Œå› ä¸ºå®ƒæ˜¯æœ¬åœ°å®ä¾‹
        if engine == "searxng":
            rate_limit = 0.5  # 0.5ç§’
        
        return time.time() - last_time >= rate_limit

    def _is_safe_url(self, url: str) -> bool:
        """URLå®‰å…¨æ£€æŸ¥"""
        try:
            # åŸºæœ¬URLæ ¼å¼æ£€æŸ¥
            if not url.startswith(("http://", "https://")):
                return False

            # æ£€æŸ¥æ˜¯å¦ä¸ºå†…ç½‘åœ°å€
            import ipaddress
            from urllib.parse import urlparse

            parsed = urlparse(url)
            hostname = parsed.hostname

            if not hostname:
                return False

            # å…è®¸localhostå’Œsearxngæœ¬åœ°å®ä¾‹
            if hostname in ["localhost", "127.0.0.1", "::1"]:
                return True

            # æ£€æŸ¥æ˜¯å¦ä¸ºç§æœ‰IP
            try:
                ip = ipaddress.ip_address(hostname)
                if ip.is_private:
                    return self.safety_guard.allow_local_network
            except ValueError:
                # ä¸æ˜¯IPåœ°å€ï¼Œæ˜¯åŸŸå
                pass

            # é»˜è®¤å…è®¸
            return True

        except Exception:
            return False

    async def _search_searxng(
        self, query: str, max_results: int, safe_search: bool
    ) -> Dict[str, Any]:
        """ä½¿ç”¨searXNGæœç´¢"""
        try:
            base_url = self.search_engines["searxng"]["url"]
            search_url = f"{base_url}/search"

            # æ ¹æ®searXNGæ–‡æ¡£ä½¿ç”¨æ­£ç¡®çš„å‚æ•°
            # https://docs.searxng.org/dev/search_api.html
            base_params = {
                "q": query,
                "format": "json",
                "categories": "general",
                "language": "auto",  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
                "safesearch": 1 if safe_search else 0,
                "pageno": 1,  # ç¬¬ä¸€é¡µ
            }
            
            # å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
            param_variations = [
                base_params,  # åŸå§‹å‚æ•°
                {**base_params, "format": "html"},  # å°è¯•HTMLæ ¼å¼
                {k: v for k, v in base_params.items() if k != "format"},  # æ— formatå‚æ•°
                {**base_params, "engines": "google,duckduckgo,bing"},  # æŒ‡å®šå¼•æ“
            ]

            # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
            from config import settings
            web_timeout = settings.timeouts.web_request
            client_timeout = aiohttp.ClientTimeout(total=web_timeout)
            
            last_error = None
            for i, test_params in enumerate(param_variations):
                try:
                    print(f"ğŸ” å°è¯•å‚æ•°ç»„åˆ {i+1}: {test_params}")
                    # ç¡®ä¿sessionå­˜åœ¨
                    if self.session is None:
                        await self._ensure_session()
                    # ç±»å‹æ£€æŸ¥å™¨éœ€è¦çŸ¥é“sessionä¸ä¸ºNone
                    session = self.session
                    assert session is not None, "Session should be initialized"
                    async with session.get(
                        search_url, params=test_params, timeout=client_timeout
                    ) as response:
                        if response.status == 200:
                            content_type = response.headers.get("content-type", "").lower()
                            
                            if "application/json" in content_type:
                                data = await response.json()
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
                                if data.get("error"):
                                    last_error = f"SearXNGé”™è¯¯: {data.get('error')}"
                                    continue
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
                                results = data.get("results", [])
                                if not results:
                                    last_error = "SearXNGè¿”å›ç©ºç»“æœ"
                                    continue
                                
                                # å¤„ç†ç»“æœ
                                processed_results = []
                                for item in results[:max_results]:
                                    processed_results.append({
                                        "title": item.get("title", ""),
                                        "url": item.get("url", ""),
                                        "content": item.get("content", ""),
                                        "engine": item.get("engine", "searxng"),
                                        "score": item.get("score", 0),
                                    })
                                
                                return {
                                    "success": True,
                                    "engine": "searxng",
                                    "query": query,
                                    "results": processed_results,
                                    "total_results": len(processed_results),
                                }
                            else:
                                # å°è¯•è§£æHTMLå“åº”
                                html = await response.text()
                                # ç®€å•æå–ç»“æœï¼ˆå®é™…åº”è¯¥ç”¨BeautifulSoupç­‰åº“ï¼‰
                                import re
                                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ›´å¤æ‚
                                last_error = "SearXNGè¿”å›HTMLæ ¼å¼ï¼Œéœ€è¦è§£æ"
                                continue
                                
                        else:
                            last_error = f"SearXNG HTTPé”™è¯¯: {response.status}"
                            continue
                            
                except asyncio.TimeoutError:
                    last_error = f"å‚æ•°ç»„åˆ {i+1} è¶…æ—¶"
                    continue
                except Exception as e:
                    last_error = f"å‚æ•°ç»„åˆ {i+1} é”™è¯¯: {str(e)}"
                    continue
            
            return {
                "success": False,
                "error": f"SearXNGæœç´¢å¤±è´¥: {last_error}",
                "query": query,
                "suggestion": "è¯·æ£€æŸ¥searXNGé…ç½®å’Œç½‘ç»œè¿æ¥",
            }
            
        except Exception as e:
            return {"success": False, "error": f"SearXNGæœç´¢å¤±è´¥: {str(e)}"}

    async def web_search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """å…¼å®¹æ€§æ–¹æ³•"""
        result = await self.search_web(query, engine="searxng", max_results=max_results)

        # è½¬æ¢ä¸ºæ—§æ ¼å¼
        if result.get("success"):
            return {
                "success": True,
                "query": query,
                "results": result.get("results", []),
                "count": len(result.get("results", [])),
            }
        else:
            return {"error": result.get("error", "æœç´¢å¤±è´¥"), "success": False}

    async def search_code(
            self, query: str, language: str = "", max_results: int = 10
    ) -> Dict[str, Any]:
        """
        æœç´¢ä»£ç ç¤ºä¾‹

        Args:
            query: æœç´¢æŸ¥è¯¢
            language: ç¼–ç¨‹è¯­è¨€
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            ä»£ç æœç´¢ç»“æœ
        """
        try:
            # ä½¿ç”¨GitHub APIæœç´¢ä»£ç 
            search_query = f"{query} language:{language}" if language else query
            url = f"https://api.github.com/search/code?q={quote(search_query)}&per_page={max_results}"

            await self._ensure_session()
            # ç±»å‹æ£€æŸ¥å™¨éœ€è¦çŸ¥é“sessionä¸ä¸ºNone
            session = self.session
            assert session is not None, "Session should be initialized"

            headers = {}
            github_token = os.getenv("GITHUB_TOKEN")
            if github_token:
                headers["Authorization"] = f"token {github_token}"

            async with session.get(url, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()

                    results = []
                    for item in data.get("items", []):
                        results.append(
                            {
                                "repository": item["repository"]["full_name"],
                                "file": item["name"],
                                "path": item["path"],
                                "url": item["html_url"],
                                "description": item["repository"].get(
                                    "description", ""
                                ),
                                "stars": item["repository"].get("stargazers_count", 0),
                            }
                        )

                    return {
                        "success": True,
                        "query": query,
                        "language": language,
                        "results": results,
                        "total_count": data.get("total_count", 0),
                    }
                else:
                    return {
                        "success": False,
                        "error": f"GitHub APIé”™è¯¯: {response.status}",
                    }

        except Exception as e:
            return {"success": False, "error": f"ä»£ç æœç´¢å¤±è´¥: {str(e)}"}
    
    async def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œå…³é—­HTTPä¼šè¯"""
        if hasattr(self, 'session') and self.session and not self.session.closed:
            await self.session.close()
            self.session = None
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿ä¼šè¯è¢«å…³é—­"""
        try:
            if hasattr(self, 'session') and self.session and not self.session.closed:
                # å°è¯•åŒæ­¥å…³é—­ä¼šè¯ï¼ˆåœ¨ææ„å‡½æ•°ä¸­ä¸èƒ½ä½¿ç”¨awaitï¼‰
                import asyncio
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œå®‰æ’å¼‚æ­¥å…³é—­
                        asyncio.create_task(self.session.close())
                    else:
                        # å¦åˆ™åŒæ­¥å…³é—­
                        loop.run_until_complete(self.session.close())
                except RuntimeError:
                    # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    loop.run_until_complete(self.session.close())
                    loop.close()
        except Exception:
            pass  # å¿½ç•¥ææ„å‡½æ•°ä¸­çš„é”™è¯¯


# ä¿ç•™åŸæœ‰WebSearchToolsç±»ä»¥ä¿æŒå…¼å®¹æ€§
class WebSearchTools(WebTools):
    """å…¼å®¹æ€§ç±»,ç»§æ‰¿è‡ªWebTools"""

    def __init__(self, api_url: str = "http://localhost:8080"):
        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„project_pathå’Œsafety_guard
        from pathlib import Path

        class MockSafetyGuard:
            def is_safe_path(self, path):
                return True

        super().__init__(Path("."), MockSafetyGuard())

        # å¦‚æœæä¾›äº†searxng URL,å¯ç”¨å®ƒ
        if api_url:
            self.search_engines["searxng"]["url"] = api_url
            self.search_engines["searxng"]["enabled"] = True

    async def web_search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """å…¼å®¹æ€§æ–¹æ³•"""
        result = await self.search_web(query, engine="searxng", max_results=max_results)

        # è½¬æ¢ä¸ºæ—§æ ¼å¼
        if result.get("success"):
            return {
                "success": True,
                "query": query,
                "results": result.get("results", []),
                "count": len(result.get("results", [])),
            }
        else:
            return {"error": result.get("error", "æœç´¢å¤±è´¥"), "success": False}
